# 一个对数据科学更大的视野

我在这里不想像很多文章想要兜售什么了不得的知识，而是一个非常自我的反思，对整个行业的反思，以及一个带有宣言性质的憧憬。这篇文章即使对我的警醒也是对自己的鼓励，这是一种「哲学式」思考的实践，而不是一种技术思维。我不想把问题拆解开，不想说出它的精密，不想列出123画出一个架构图一样的模式。它仅仅是我的思考，但因为是内省的且私人的，它才显得更有价值。

现在对于数据科学的定义往往限定在以下几个领域：

1. 基于统计和业务常识的分析；
2. 对于大数据Pipe Line处理的工程项目；
3. 偏重算法涉及的深度学习/AI领域。

数据科学可能涉及到的大部分知识，我们发现都**难以落地**，唯一成功的可能就是「推荐/搜索」、图像/NLP相关的技术接口这些领域。造成这一现象的根源在于，数据科学依赖的是可观的数据和相对稳定的外部环境。我们比较下列两个任务：

1. 设计一个平台的发券方案。
2. 设计出判断一张图片是狗还是猫。

为何后者是容易的，而前者是难的。其实都体现在「数据搜集」和「外部环境的稳定性」这两点。「判断一张图片是狗还是猫」这个问题，上下文牵扯很少，几百年前的人判断一个图片是狗还是猫，与现代人的观点也大致相同。相应的，搜集「同分布」的数据也相对简单，几十年前的图片和昨天的图片，都可以用；而且一旦被判定为有效数据，则可以一直使用。

相反，发券这件事难度很大。主要问题是外部环境改变很大，比如最近疫情导致了食物需求的增加，发券理应可以通过这个角度增加刺激。但事实上，这类事件很有可能就出现一次，且每天都在变化。比如疫情发展之后，食物供应马上恢复了正常。这样需求又没了。这就导致，我们训练的模型必须非常快地响应，且时间敏感。很多突发事件的发生总是来得很快，且很少重复（「历史永不重复」马克·吐温语）。当然，退而求其次，快速地搜集数据，线上训练更新也不错。但这仅仅对大平台也有，而且，外部环境的变化是不是导致之前的数据无法使用，特征是否需要变更也是未知的。这些都越发增加了难度。

这两个特征都让我们体验到一个事，数据模型是滞后的，它不太可能第一时间获取到世界的特征。甚至和我们普通人一样，普通人对历史的敏感性往往要滞后很久才能体验到。比如疫情对经济影响。当然我们可以通过理性推理预测变化的未来，但这就是直觉了。这是所有做深度学习、统计学之类最怕的领地，他们期待所有可以准确量化的环境，然后无脑地套用模型，只是对模型结构做更多的调整。可以想象，我们一大堆的数据模型，在极度变化的世界中会马上适应不良，甚至，积累的那些数据因为不符合现在的局势，显得不再重要。

所有上面说的东西，都违反我们在入这个行业时接受的知识：数据可以带来前瞻性思考；我们应当积累尽可能多的数据，他们都是有用的。

现在要问的是，如果我在一个StartUp公司工作，没有任何数据，连商业模式都没有被认证；我在一个创意文化工作，制作的产品可能要2年后才能上线，而我即使分析出了现在主流的产品，但能保证能对付2年后人们的口味吗（思考游戏、电影行业）。在这些情况中，数据是不是真的有效？

这里，我们画了一个圈，一个限制。最后发现，数据科学行业最后的方向只能是：低技术高业务形态的数据分析以及高技术很难落地的AI行业，最后就是为了基建诞生的大数据工程行业。这就是现在的结果。

我们有没有突围的方法？数据科学是否适合更多的行业、领域？当然，我这里指的是技术层面的实践，而不是我在[数据科学这些年的变化](../reflections/ds-progress.md)里表述的做一个懂数据的运营或产品。越快越新越小的行业，我们越需要的不确定性和直觉更多，并且需要更多的团队影响力。而越大越成熟的行业，我们需要的是某种「自动化」的无心智活动，数据科学解决的是规模问题，直觉和不确定性在其中起到作用往往是结构框架层面的，而不是新的尝试层面的。数据科学的发展事实上，需要这两个方向的发展。在没有数据时，我们需要更多的假设、仿真、模拟、数据生成方法；在数据少的时候需要更多的推理、统计推断；而数据更多的时候则是需要工程层面和架构层面的解决方案。这三个方向才是一个完整的数据科学。而对现在世界局势、政策变化，以及产业转型的角度来看，更多的直觉、推理可能更加关键，而不是一个滞后的数据中台。
